---
title: On Building Trustworthy AI Systems
date: 2025-01-20
---

ON BUILDING TRUSTWORTHY AI SYSTEMS
===
2025.01.20

---

The gap between a model that performs well on benchmarks and one you can deploy with confidence is vast. I spent two years learning this.

At Northrop, we had a saying:

    "Demo magic isn't production magic."

A system that impresses in controlled conditions will find creative ways to fail when facing real-world data, adversarial inputs, and edge cases no one anticipated.


THE VERIFICATION PROBLEM
---

Traditional software: you write tests, prove properties, trace execution paths.

Neural networks: you deploy a function you don't fully understand, trained on data you can't fully audit, making decisions you can't fully explain.

This isn't an argument against deploying AI. It's an argument for humility.


    ┌─────────────────────────────────────────┐
    │  "All models are wrong, some useful."   │
    │                         — George Box    │
    │                                         │
    │  "All models are wrong, and some will   │
    │   fail at 3 AM on a holiday weekend."   │
    │                         — Everyone      │
    └─────────────────────────────────────────┘


WHAT ACTUALLY WORKS
---

After numerous incidents and post-mortems:

  ► Confidence calibration
    If your model says 90% sure, it should be right 90% of the time. Most aren't.

  ► Anomaly detection on inputs
    Know when you're seeing data unlike your training distribution.

  ► Human-in-the-loop for high stakes
    Not as a crutch. As a circuit breaker.

  ► Extensive logging
    You can't debug what you didn't record.


---

We're building tools, not oracles.

← BACK TO WRITING
